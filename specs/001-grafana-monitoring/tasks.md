# Tasks: Grafana Monitoring Dashboard

**Input**: Design documents from `/specs/001-grafana-monitoring/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/

**Tests**: Integration tests for container and data source connectivity are included to verify the monitoring infrastructure.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

## Path Conventions

- **Monitoring service**: `grafana/` at repository root
- **Tests**: `tests/integration/` at repository root
- **Configuration**: `grafana/provisioning/` for Grafana provisioning files

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and basic structure

- [X] T001 Create Grafana directory structure: grafana/provisioning/datasources/, grafana/provisioning/dashboards/, grafana/dashboards/
- [X] T002 [P] Add Grafana environment variables to env.example: GRAFANA_PORT, GRAFANA_ADMIN_USER, GRAFANA_ADMIN_PASSWORD, GRAFANA_POSTGRES_USER, GRAFANA_POSTGRES_PASSWORD
- [X] T003 [P] Create Dockerfile for Grafana service in grafana/Dockerfile (or use official image in docker-compose.yml)

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**âš ï¸ CRITICAL**: No user story work can begin until this phase is complete

- [X] T004 Create read-only PostgreSQL user for Grafana monitoring: Create migration script in ws-gateway/migrations/ (following constitution: all PostgreSQL migrations must be in ws-gateway service). Migration should create user `grafana_monitor` with read-only permissions (SELECT on trading_signals, orders, execution_events, model_versions, model_quality_metrics, subscriptions tables)
- [X] T005 Add Grafana service to docker-compose.yml with port mapping, environment variables, volumes, and health check
- [X] T006 [P] Create PostgreSQL data source provisioning file in grafana/provisioning/datasources/datasources.yml with connection configuration
- [X] T007 [P] Create RabbitMQ HTTP API data source provisioning entry in grafana/provisioning/datasources/datasources.yml for queue monitoring
- [X] T008 [P] Create service health HTTP data source provisioning entries in grafana/provisioning/datasources/datasources.yml for ws-gateway, model-service, order-manager
- [X] T009 Create dashboard provisioning configuration file in grafana/provisioning/dashboards/dashboards.yml
- [X] T010 [P] Create integration test file tests/integration/test_grafana_container.py to verify Grafana container starts and health endpoint responds
- [X] T011 [P] Create integration test file tests/integration/test_grafana_datasources.py to verify data source connectivity (PostgreSQL, RabbitMQ, service endpoints)

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - View Recent Trading Signals (Priority: P1) ğŸ¯ MVP

**Goal**: Traders and operators can view a list of recent trading signals generated by the model, including signal details such as asset, side, price, confidence, and timestamp, to monitor model activity and decision-making in real-time.

**Independent Test**: Access Grafana dashboard and verify that recent trading signals are displayed in a table format with all required fields (signal ID, asset, side, price, confidence, timestamp, strategy ID). Dashboard delivers immediate visibility into model activity without requiring any system modifications.

### Implementation for User Story 1

- [X] T012 [US1] Create Trading Signals dashboard panel JSON in grafana/dashboards/trading-signals-panel.json with PostgreSQL query for recent signals from trading_signals table
- [X] T013 [US1] Add Trading Signals panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json with table visualization showing signal_id, asset, side, price, confidence, timestamp, strategy_id
- [X] T014 [US1] Configure dashboard panel query in grafana/dashboards/trading-system-monitoring.json to use PostgreSQL data source with SQL query from data-model.md querying trading_signals table (last 100 signals, prioritizing quantity)
- [X] T015 [US1] Add auto-refresh configuration to Trading Signals panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Story 1 should be fully functional and testable independently

---

## Phase 4: User Story 2 - Monitor Order Execution Status (Priority: P1)

**Goal**: Traders and operators can view a list of recent orders with information about how each order was closed (filled, cancelled, rejected, etc.), including execution details such as execution price, quantity, fees, and performance metrics, to track trading outcomes and identify execution issues.

**Independent Test**: Access Grafana dashboard and verify that recent orders are displayed with execution status, closure information, and performance metrics. Dashboard delivers immediate visibility into order execution outcomes without requiring any system modifications.

### Implementation for User Story 2

- [X] T016 [P] [US2] Create Order Execution dashboard panel JSON in grafana/dashboards/order-execution-panel.json with PostgreSQL query joining execution_events and orders tables
- [X] T017 [US2] Add Order Execution panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json with table visualization showing order_id, signal_id, asset, side, execution_price, execution_quantity, execution_fees, executed_at, closure_status
- [X] T018 [US2] Configure dashboard panel query in grafana/dashboards/trading-system-monitoring.json to use PostgreSQL data source with SQL query from data-model.md (last 100 orders, prioritizing quantity)
- [X] T019 [US2] Add auto-refresh configuration to Order Execution panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently

---

## Phase 5: User Story 3 - Monitor Model State and Quality Metrics (Priority: P2)

**Goal**: Traders and operators can view the current state of the trading model, including active model version, training status, and basic quality metrics (e.g., win rate, accuracy, total PnL), to assess model performance and determine if retraining or intervention is needed.

**Independent Test**: Access Grafana dashboard and verify that model state information and quality metrics are displayed. Dashboard delivers visibility into model health and performance trends without requiring any system modifications.

### Implementation for User Story 3

- [ ] T020 [P] [US3] Create Model State dashboard panel JSON in grafana/dashboards/model-state-panel.json with PostgreSQL query for active model versions from model_versions table
- [ ] T021 [P] [US3] Create Model Quality Metrics dashboard panel JSON in grafana/dashboards/model-quality-panel.json with PostgreSQL query calculating win rate, total orders, successful orders, total PnL from execution_events and model_quality_metrics tables
- [ ] T022 [US3] Add Model State panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json showing active_model_version, strategy_id, training_status, warmup_mode_status
- [ ] T023 [US3] Add Model Quality Metrics panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json showing win_rate, total_orders_count, successful_orders_count, total_pnl
- [ ] T024 [US3] Configure dashboard panel queries in grafana/dashboards/trading-system-monitoring.json to use PostgreSQL data source with SQL queries from data-model.md
- [ ] T025 [US3] Add auto-refresh configuration to Model State and Quality Metrics panels in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Stories 1, 2, AND 3 should all work independently

---

## Phase 6: User Story 4 - Detect RabbitMQ Queue Lags (Priority: P2)

**Goal**: Operators can monitor RabbitMQ queue lengths and message processing rates to detect when queues are backing up, indicating that consumers are not processing messages fast enough or have stopped consuming, which could cause system delays or data loss.

**Independent Test**: Access Grafana dashboard and verify that RabbitMQ queue metrics (queue length, message rate, consumer count) are displayed for all relevant queues. Dashboard delivers immediate visibility into queue health without requiring any system modifications.

### Implementation for User Story 4

- [ ] T026 [P] [US4] Create RabbitMQ Queue Metrics dashboard panel JSON in grafana/dashboards/queue-metrics-panel.json with HTTP data source query to RabbitMQ Management API /api/queues endpoint
- [ ] T027 [US4] Add Queue Metrics panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json with table visualization showing queue_name, queue_length, message_publish_rate, message_consume_rate, consumer_count, lag_detected
- [ ] T028 [US4] Configure dashboard panel query in grafana/dashboards/trading-system-monitoring.json to use RabbitMQ HTTP API data source with Basic Auth authentication
- [ ] T029 [US4] Add lag detection calculation in dashboard panel: queue_length > 1000 OR (consume_rate / publish_rate < 0.1) with visual indicator (color coding)
- [ ] T030 [US4] Add auto-refresh configuration to Queue Metrics panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Stories 1, 2, 3, AND 4 should all work independently

---

## Phase 7: User Story 5 - Monitor System Health Status (Priority: P1)

**Goal**: Operators can view the overall health status of the trading system and health status broken down by individual services, along with error statistics or lists, to quickly identify which services are healthy and which are experiencing issues.

**Independent Test**: Access Grafana dashboard and verify that health status is displayed for all services and the overall system. Dashboard delivers immediate visibility into system health without requiring any system modifications.

### Implementation for User Story 5

- [ ] T031 [P] [US5] Create System Health dashboard panel JSON in grafana/dashboards/system-health-panel.json with HTTP data source queries to service health endpoints (ws-gateway, model-service, order-manager, postgres, rabbitmq)
- [ ] T032 [US5] Add System Health panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json with table visualization showing service_name, overall_status, component_statuses (database, queue, websocket), error_information
- [ ] T033 [US5] Configure dashboard panel queries in grafana/dashboards/trading-system-monitoring.json to use service health HTTP data sources (ws-gateway Health, model-service Health, order-manager Health)
- [ ] T034 [US5] Add overall system health aggregation logic: healthy if all services are healthy, unhealthy if any service is unhealthy
- [ ] T035 [US5] Add visual indicators (color coding: green for healthy, red for unhealthy) to System Health panel in grafana/dashboards/trading-system-monitoring.json
- [ ] T036 [US5] Add auto-refresh configuration to System Health panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Stories 1, 2, 3, 4, AND 5 should all work independently

---

## Phase 8: User Story 6 - Monitor WebSocket Connection to Bybit Exchange (Priority: P2)

**Goal**: Operators can monitor the WebSocket connection status and metrics for the connection to Bybit exchange, including connection state, reconnection attempts, heartbeat status, and active subscriptions, to ensure data flow from the exchange is uninterrupted.

**Independent Test**: Access Grafana dashboard and verify that WebSocket connection metrics are displayed. Dashboard delivers immediate visibility into connection health without requiring any system modifications.

### Implementation for User Story 6

- [ ] T037 [P] [US6] Create WebSocket Connection Metrics dashboard panel JSON in grafana/dashboards/websocket-connection-panel.json with HTTP data source query to ws-gateway /health endpoint
- [ ] T038 [US6] Add WebSocket Connection panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json showing connection_status, environment, connection_duration, last_heartbeat_timestamp, reconnection_count, last_error_message, active_subscriptions_count
- [ ] T039 [US6] Configure dashboard panel query in grafana/dashboards/trading-system-monitoring.json to use ws-gateway Health HTTP data source and extract websocket_state fields from JSON response
- [ ] T040 [US6] Add connection duration calculation: current_time - connected_at timestamp
- [ ] T041 [US6] Add visual indicators for connection status (connected=green, disconnected=red, connecting/reconnecting=yellow) in grafana/dashboards/trading-system-monitoring.json
- [ ] T042 [US6] Add auto-refresh configuration to WebSocket Connection panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)

**Checkpoint**: At this point, User Stories 1, 2, 3, 4, 5, AND 6 should all work independently

---

## Phase 9: User Story 7 - View Recent Key Events History (Priority: P2)

**Goal**: Operators can view a chronological history of recent key system events, including trading signals received, orders created/executed/closed, model training/retraining events, WebSocket subscription changes, and other significant system state changes, to understand system activity and trace the sequence of events leading to current system state.

**Independent Test**: Access Grafana dashboard and verify that recent key events are displayed in chronological order with event type, timestamp, and relevant details. Dashboard delivers immediate visibility into system activity without requiring any system modifications.

### Implementation for User Story 7

- [ ] T043 [P] [US7] Create Event History dashboard panel JSON in grafana/dashboards/event-history-panel.json with PostgreSQL query aggregating events from multiple tables (execution_events, orders, model_versions, subscriptions)
- [ ] T044 [US7] Add Event History panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json with table visualization showing event_type, event_timestamp, event_id, related_entity_ids, event_details, service_name
- [ ] T045 [US7] Configure dashboard panel query in grafana/dashboards/trading-system-monitoring.json to use PostgreSQL data source with unified SQL query from data-model.md (UNION ALL of event types, last 200 events, prioritizing quantity)
- [ ] T046 [US7] Add event filtering capabilities to Event History panel: filter by event_type (signal, order, model training, subscription, connection) and by service_name (model-service, order-manager, ws-gateway)
- [ ] T047 [US7] Add auto-refresh configuration to Event History panel in grafana/dashboards/trading-system-monitoring.json (60 seconds interval)
- [ ] T048 [US7] Add chronological sorting (event_timestamp DESC) to Event History panel query in grafana/dashboards/trading-system-monitoring.json

**Checkpoint**: At this point, all user stories should be independently functional

---

## Phase 10: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories

- [ ] T049 [P] Update README.md with Grafana monitoring service documentation including setup instructions, access information, and dashboard descriptions
- [ ] T050 [P] Update quickstart.md with Grafana deployment steps and verification procedures
- [ ] T051 [P] Create comprehensive dashboard JSON file grafana/dashboards/trading-system-monitoring.json combining all panels from user stories with proper layout and organization
- [ ] T052 [P] Add error handling and graceful degradation configuration to dashboard panels: show connection status indicators, display cached data when data sources unavailable
- [ ] T053 [P] Configure dashboard-level auto-refresh settings in grafana/dashboards/trading-system-monitoring.json (default 60 seconds, configurable)
- [ ] T054 [P] Add dashboard time range presets (Last 1 hour, Last 24 hours, Last 7 days) to grafana/dashboards/trading-system-monitoring.json
- [ ] T055 [P] Update integration tests in tests/integration/test_grafana_datasources.py to verify all data sources connect successfully
- [ ] T056 [P] Create integration test in tests/integration/test_grafana_dashboard.py to verify dashboard loads and all panels render correctly
- [ ] T057 [P] Add Grafana volume to docker-compose.yml volumes section for persistent Grafana data storage
- [ ] T058 [P] Verify all environment variables are documented in env.example with descriptions
- [ ] T059 Run quickstart.md validation: verify all deployment steps work correctly
- [ ] T060 [P] Add security documentation: change default credentials, network access considerations, credential management best practices

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-9)**: All depend on Foundational phase completion
  - User stories can then proceed in parallel (if staffed)
  - Or sequentially in priority order (P1 â†’ P2)
- **Polish (Phase 10)**: Depends on all desired user stories being complete

### User Story Dependencies

- **User Story 1 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 2 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 3 (P2)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 4 (P2)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 5 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 6 (P2)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 7 (P2)**: Can start after Foundational (Phase 2) - No dependencies on other stories

### Within Each User Story

- Dashboard panel JSON files can be created in parallel
- Panel configuration and queries can be added independently
- Auto-refresh configuration can be added after panel creation

### Parallel Opportunities

- All Setup tasks marked [P] can run in parallel
- All Foundational tasks marked [P] can run in parallel (within Phase 2)
- Once Foundational phase completes, all user stories can start in parallel (if team capacity allows)
- Dashboard panel JSON files within a story marked [P] can run in parallel
- Different user stories can be worked on in parallel by different team members
- All Polish tasks marked [P] can run in parallel

---

## Parallel Example: User Story 1

```bash
# Launch all panel creation tasks for User Story 1 together:
Task: "Create Trading Signals dashboard panel JSON in grafana/dashboards/trading-signals-panel.json"
Task: "Add Trading Signals panel to main dashboard JSON file grafana/dashboards/trading-system-monitoring.json"
```

---

## Parallel Example: User Story 3

```bash
# Launch all panel creation tasks for User Story 3 together:
Task: "Create Model State dashboard panel JSON in grafana/dashboards/model-state-panel.json"
Task: "Create Model Quality Metrics dashboard panel JSON in grafana/dashboards/model-quality-panel.json"
```

---

## Implementation Strategy

### MVP First (User Stories 1, 2, 5 Only - All P1)

1. Complete Phase 1: Setup
2. Complete Phase 2: Foundational (CRITICAL - blocks all stories)
3. Complete Phase 3: User Story 1 (Trading Signals)
4. Complete Phase 4: User Story 2 (Order Execution)
5. Complete Phase 7: User Story 5 (System Health)
6. **STOP and VALIDATE**: Test all P1 stories independently
7. Deploy/demo if ready

### Incremental Delivery

1. Complete Setup + Foundational â†’ Foundation ready
2. Add User Story 1 â†’ Test independently â†’ Deploy/Demo (Basic MVP!)
3. Add User Story 2 â†’ Test independently â†’ Deploy/Demo
4. Add User Story 5 â†’ Test independently â†’ Deploy/Demo (Full P1 MVP!)
5. Add User Story 3 â†’ Test independently â†’ Deploy/Demo
6. Add User Story 4 â†’ Test independently â†’ Deploy/Demo
7. Add User Story 6 â†’ Test independently â†’ Deploy/Demo
8. Add User Story 7 â†’ Test independently â†’ Deploy/Demo
9. Each story adds value without breaking previous stories

### Parallel Team Strategy

With multiple developers:

1. Team completes Setup + Foundational together
2. Once Foundational is done:
   - Developer A: User Story 1 (Trading Signals)
   - Developer B: User Story 2 (Order Execution)
   - Developer C: User Story 5 (System Health)
3. After P1 stories complete:
   - Developer A: User Story 3 (Model State/Metrics)
   - Developer B: User Story 4 (Queue Lags)
   - Developer C: User Story 6 (WebSocket Connection)
   - Developer D: User Story 7 (Event History)
4. Stories complete and integrate independently

---

## Notes

- [P] tasks = different files, no dependencies
- [Story] label maps task to specific user story for traceability
- Each user story should be independently completable and testable
- Dashboard panels can be created and tested independently
- All dashboard panels are combined into a single dashboard JSON file
- Verify data source connectivity before creating dashboard panels
- Commit after each task or logical group
- Stop at any checkpoint to validate story independently
- Avoid: vague tasks, same file conflicts, cross-story dependencies that break independence
- Grafana provisioning files are version-controlled and applied automatically on container startup
- No custom application code required - Grafana container with provisioning files is sufficient

---

## Task Summary

- **Total Tasks**: 60
- **Setup Tasks**: 3
- **Foundational Tasks**: 8
- **User Story 1 Tasks**: 4
- **User Story 2 Tasks**: 4
- **User Story 3 Tasks**: 6
- **User Story 4 Tasks**: 5
- **User Story 5 Tasks**: 6
- **User Story 6 Tasks**: 6
- **User Story 7 Tasks**: 6
- **Polish Tasks**: 12

**Parallel Opportunities**:

- 3 tasks in Setup phase
- 4 tasks in Foundational phase
- Multiple dashboard panel creation tasks within each user story
- All user stories can proceed in parallel after Foundational phase
- 8 tasks in Polish phase

**Suggested MVP Scope**: User Stories 1, 2, and 5 (all P1 priorities) - provides trading signals, order execution, and system health monitoring

**Independent Test Criteria**:

- US1: Verify Trading Signals panel displays recent signals with all required fields
- US2: Verify Order Execution panel displays recent orders with execution status
- US3: Verify Model State and Quality Metrics panels display model information
- US4: Verify Queue Metrics panel displays queue health and lag detection
- US5: Verify System Health panel displays service health status
- US6: Verify WebSocket Connection panel displays connection metrics
- US7: Verify Event History panel displays chronological event list with filtering
