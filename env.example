# =============================================================================
# Bybit API Configuration
# =============================================================================
# Bybit API credentials for WebSocket authentication and REST API (optional for public endpoints)
# Use testnet for development, mainnet for production
# Note: API keys are optional for public market data endpoints (used by backfilling service)
BYBIT_API_KEY=XXXX
BYBIT_API_SECRET=XXXX
BYBIT_ENVIRONMENT=testnet  # or 'mainnet' for production

# =============================================================================
# Database Configuration (PostgreSQL)
# =============================================================================
# Shared PostgreSQL database for all microservices
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=XXXX
POSTGRES_USER=XXXX
POSTGRES_PASSWORD=XXXX

# =============================================================================
# RabbitMQ Configuration
# =============================================================================
# Message broker for event-driven communication
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=XXXX
RABBITMQ_PASSWORD=XXXX

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis for distributed locking (used by order-manager) and caching (used by feature-service)
# PRIMARY cache for feature-service dataset building (recommended for all deployments)
# Redis provides persistence and distributed caching across container restarts
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
# Redis connection pool settings
REDIS_MAX_CONNECTIONS=10
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5
# Enable Redis as primary cache (default: true). If false, will use memory cache only.
# Memory cache is FALLBACK only - used automatically when Redis unavailable
# Memory cache limitations: lost on restart, single instance only
CACHE_REDIS_ENABLED=true

# =============================================================================
# WebSocket Gateway Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4400)
WS_GATEWAY_PORT=4400

# WebSocket Gateway hostname (for model-service to subscribe to channels)
WS_GATEWAY_HOST=ws-gateway

# WebSocket Gateway URL (for position-manager and other services to call REST API)
# Default: http://ws-gateway:4400 (internal Docker network)
WS_GATEWAY_URL=http://ws-gateway:4400

# API key for REST API authentication
# Other microservices use this key to manage subscriptions
WS_GATEWAY_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
WS_GATEWAY_LOG_LEVEL=INFO

# Service identifier
WS_GATEWAY_SERVICE_NAME=ws-gateway

# WebSocket connection strategy: 'dual' (separate public/private connections) or 'single' (one private connection for all)
# Default: 'dual' - recommended for better scalability and separation of concerns
# 'single' mode uses only private endpoint for backward compatibility
BYBIT_WS_STRATEGY=dual  # or 'single'

# Bybit public WebSocket category: 'spot', 'linear', 'inverse', 'option', 'spread'
# Default: 'linear' for unified trading (USDT/USDC perpetual & futures)
# Use 'spot' for spot trading, 'linear' for unified trading
BYBIT_WS_PUBLIC_CATEGORY=linear  # or 'spot', 'inverse', 'option', 'spread'

# Bybit market category for REST API requests (kline, tickers, instruments-info, etc.)
# Must match the category used for trading (order-manager) and feature computation (feature-service)
# Default: 'linear' for unified trading (USDT/USDC perpetual & futures)
# Use 'spot' for spot trading, 'linear' for unified trading
# IMPORTANT: This must be consistent across feature-service and order-manager
BYBIT_MARKET_CATEGORY=linear  # or 'spot', 'linear', 'inverse', 'option', 'spread'

# =============================================================================
# Model Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4500)
MODEL_SERVICE_PORT=4500
TARGET_REGISTRY_VERSION=latest

# API key for REST API authentication
# Other microservices use this key to authenticate with Model Service
MODEL_SERVICE_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
MODEL_SERVICE_LOG_LEVEL=INFO

# Service identifier
MODEL_SERVICE_SERVICE_NAME=model-service

# =============================================================================
# Feature Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4900)
FEATURE_SERVICE_PORT=4900

# Feature Service hostname (for REST API calls and model-service to connect)
FEATURE_SERVICE_HOST=feature-service

# API key for REST API authentication
# Other microservices use this key to authenticate with Feature Service
FEATURE_SERVICE_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
FEATURE_SERVICE_LOG_LEVEL=INFO

# Service identifier
FEATURE_SERVICE_SERVICE_NAME=feature-service

# Enable queue subscription for real-time features (true) or use REST API polling (false)
# Default: true - use RabbitMQ queue 'features.live' for real-time features
FEATURE_SERVICE_USE_QUEUE=true

# Feature cache TTL in seconds for real-time feature vectors
# Features older than this value are considered stale
FEATURE_SERVICE_FEATURE_CACHE_TTL_SECONDS=30

# Timeout in seconds for feature requests to Feature Service API (default: 60 seconds)
# Increase if feature-service is slow to respond or times out frequently
FEATURE_SERVICE_FEATURE_TIMEOUT_SECONDS=60

# Maximum wait time in seconds for dataset building request (default: 1 hour)
FEATURE_SERVICE_DATASET_BUILD_TIMEOUT_SECONDS=3600

# Timeout in seconds for getting dataset metadata from Feature Service API (default: 60 seconds)
# Increase if you experience timeout errors when fetching dataset metadata
FEATURE_SERVICE_DATASET_METADATA_TIMEOUT_SECONDS=60

# Timeout in seconds for downloading dataset files from Feature Service API (default: 600 seconds = 10 minutes)
# Increase for very large datasets or slow network connections
FEATURE_SERVICE_DATASET_DOWNLOAD_TIMEOUT_SECONDS=600

# Polling interval in seconds for checking dataset build status
# Used when waiting for dataset.ready notification
FEATURE_SERVICE_DATASET_POLL_INTERVAL_SECONDS=60

# Storage path for downloaded dataset files (Parquet format)
# Datasets are downloaded from Feature Service and stored locally for training
FEATURE_SERVICE_DATASET_STORAGE_PATH=/datasets

# Legacy feature compatibility mode (for models trained before Feature Service integration)
# Set to 'true' only if you have old models that require legacy feature names (e.g., spread_percent)
# New models should be trained on Feature Service features directly (set to 'false')
# WARNING: This is a temporary workaround. Models should be retrained on Feature Service features.
FEATURE_SERVICE_LEGACY_FEATURE_COMPATIBILITY=false

# =============================================================================
# Raw Data Storage Configuration
# =============================================================================
# Base directory for raw market data storage (Parquet files)
# Data is organized by type and date: data/raw/{type}/{date}/{symbol}.parquet
RAW_DATA_STORAGE_PATH=/data/raw

# Data retention period in days (default: 90 days)
RAW_DATA_RETENTION_DAYS=90

# =============================================================================
# Dataset Storage Configuration
# =============================================================================
# Base directory for dataset storage (Parquet files)
# Datasets are stored as: data/datasets/{dataset_id}/{split}.parquet
DATASET_STORAGE_PATH=/data/datasets

# =============================================================================
# Feature Registry Configuration
# =============================================================================
# Path to default Feature Registry YAML configuration file
FEATURE_REGISTRY_CONFIG_PATH=/app/config/feature_registry.yaml

# Feature Registry Version Management Configuration
# Directory for Feature Registry version files (YAML files stored as source of truth)
FEATURE_REGISTRY_VERSIONS_DIR=/app/config/versions

# Use database-driven version management (true) or file-only mode (false)
# Default: true - enables version management via database with files as source of truth
FEATURE_REGISTRY_USE_DB=true

# Automatically migrate legacy feature_registry.yaml to versioned storage on startup
# Default: true - automatically migrates existing feature_registry.yaml to versions/ directory
FEATURE_REGISTRY_AUTO_MIGRATE=true

# =============================================================================
# Feature Computation Configuration
# =============================================================================
# NOTE: Feature computation intervals are computed dynamically from Feature Registry
# and Target Registry. No manual configuration needed.
# Intervals are determined by:
# - Feature Registry: lookback_window requirements of features
# - Target Registry: prediction horizon (horizon in seconds)
# If registries are unavailable, default intervals (1s, 3s, 15s, 1m) are used.

# Latency warning threshold in milliseconds (default: 70ms)
FEATURE_COMPUTATION_LATENCY_WARNING_MS=70

# =============================================================================
# Data Quality Configuration
# =============================================================================
# Enable data quality monitoring (default: true)
DATA_QUALITY_MONITORING_ENABLED=true

# Data quality report generation timeout in seconds (default: 5 seconds)
DATA_QUALITY_REPORT_TIMEOUT_SECONDS=5

# =============================================================================
# Symbols Configuration
# =============================================================================
# Comma-separated list of symbols to process (e.g., BTCUSDT,ETHUSDT)
# If empty, service will subscribe to all available symbols from ws-gateway
FEATURE_SERVICE_SYMBOLS=

# =============================================================================
# Historical Data Backfilling Configuration
# =============================================================================
# Delay between API requests in milliseconds to respect rate limits (default: 100ms)
# Used by backfilling service when fetching historical data from Bybit REST API
FEATURE_SERVICE_BACKFILL_RATE_LIMIT_DELAY_MS=100
# Enable/disable backfilling feature (default: true)
FEATURE_SERVICE_BACKFILL_ENABLED=true
# Enable/disable automatic backfilling when data insufficient (default: true)
FEATURE_SERVICE_BACKFILL_AUTO=true
# Maximum days to backfill in one operation (default: 90)
FEATURE_SERVICE_BACKFILL_MAX_DAYS=40
# Default kline interval in minutes for backfilling (default: 1 = 1 minute)
FEATURE_SERVICE_BACKFILL_DEFAULT_INTERVAL=1
# Note: Backfilling uses Bybit REST API public endpoints and does not require API keys for market data

# =============================================================================
# Model Storage Configuration
# =============================================================================
# Directory for model files (mounted as Docker volume)
MODEL_STORAGE_PATH=/models

# =============================================================================
# Model Training Configuration
# =============================================================================
# Minimum number of records required to start model training
MODEL_TRAINING_MIN_DATASET_SIZE=1000

# Maximum duration for model training in seconds (30 minutes default)
MODEL_TRAINING_MAX_DURATION_SECONDS=1800

# Minimum threshold for model activation (0.0 to 1.0)
# Model Quality Thresholds for Auto-Activation
# Minimum threshold for classification models (0.0 - 1.0, default: 0.75 = 75%)
# Used with metric from MODEL_TRAINING_THRESHOLD_OPTIMIZATION_METRIC
MODEL_ACTIVATION_THRESHOLD=0.75

# Metric to optimize for threshold calibration and model activation
# Options: 'f1', 'pr_auc', 'balanced_accuracy', 'recall'
# Default: 'f1'
MODEL_TRAINING_THRESHOLD_OPTIMIZATION_METRIC=f1

# Minimum R² score for regression models (default: 0.0 = model should be at least as good as predicting mean)
# R² > 0 means model is better than always predicting the mean value
# R² = 1.0 means perfect predictions
# R² < 0 means model is worse than predicting mean (should not be activated)
MODEL_QUALITY_THRESHOLD_R2=0.0

# Maximum RMSE for regression models (optional, default: not set)
# If set, model will be activated only if RMSE <= this value
# Example: 0.05 means RMSE should be <= 5% (0.05) for activation
# MODEL_QUALITY_THRESHOLD_RMSE=0.05

# Scheduled retraining schedule (cron format, optional)
# Example: "0 2 * * *" for daily at 2 AM

# Class Balancing Configuration
# =============================================================================
# Enable SMOTE oversampling for minority classes (default: false)
# SMOTE generates synthetic samples for minority classes to balance the dataset
# Use for severe class imbalance. Note: increases training time and memory usage
MODEL_TRAINING_USE_SMOTE=false

# Class weight calculation method for multi-class classification
# Options: "inverse_frequency" (default), "balanced" (sklearn), "custom"
# - "inverse_frequency": weight = total_samples / (num_classes * class_count)
# - "balanced": uses sklearn.utils.class_weight.compute_class_weight("balanced")
# - "custom": use custom weights from configuration (not yet implemented)
MODEL_TRAINING_CLASS_WEIGHT_METHOD=inverse_frequency

# Hyperparameter Tuning Configuration
# =============================================================================
# Enable hyperparameter optimization (default: false)
# When enabled, model training will perform hyperparameter search before training
# Note: significantly increases training time, use only for model improvement iterations
MODEL_TRAINING_HYPERPARAMETER_TUNING=false

# Hyperparameter tuning method
# Options: "grid_search" (default), "bayesian"
# - "grid_search": exhaustive search over parameter grid
# - "bayesian": Bayesian optimization using scikit-optimize or optuna
MODEL_TRAINING_TUNING_METHOD=grid_search

# Maximum iterations for hyperparameter tuning (default: 50)
# Limits the number of parameter combinations to evaluate
MODEL_TRAINING_TUNING_MAX_ITERATIONS=50

# Path to YAML file with default model hyperparameters by model/task type.
# Relative to the application working directory inside the container (/app).
MODEL_HYPERPARAMS_CONFIG_PATH=config/model_hyperparams.yaml

# Data Quality Validation Configuration
# =============================================================================
# Enable data quality checks before training (default: true)
# Checks for missing values, infinite values, constant features, duplicates, data leakage
MODEL_TRAINING_QUALITY_CHECKS_ENABLED=true

# Timestamp Continuity Validation Configuration
# =============================================================================
# Minimum acceptable timestamp coverage ratio for training datasets (0.0-1.0, default: 0.8 = 80%)
# Datasets with coverage below this ratio will trigger warnings
# Lower coverage may indicate missing data periods that could affect model training quality
MODEL_TRAINING_MIN_DATASET_COVERAGE_RATIO=0.8

# Enable warnings for large timestamp gaps in training datasets (default: true)
# Large gaps may indicate missing trading sessions or data collection issues
MODEL_TRAINING_WARN_ON_LARGE_GAPS=true

# Critical gap threshold in seconds (default: 3600 = 1 hour)
# Gaps exceeding this duration will trigger warnings
# Gaps larger than this may significantly affect temporal dependencies in model training
MODEL_TRAINING_CRITICAL_GAP_THRESHOLD_SECONDS=3600

# =============================================================================
# Time-Based Retraining Configuration (for market-data-only training)
# =============================================================================
# Interval in days for time-based retraining (default: 7 days)
# Model will be retrained when this many days have passed since last training
MODEL_RETRAINING_INTERVAL_DAYS=7

# Interval in hours for checking if retraining is needed (default: 6 hours)
# Background task checks database every N hours to see if retraining interval has passed
MODEL_RETRAINING_CHECK_INTERVAL_HOURS=6

# Version Mismatch Auto-Retraining Configuration
# Minimum hours between automatic retraining triggers due to version mismatches (default: 24 hours)
# Prevents spam retraining when feature/target registry versions change frequently
# When version mismatch is detected, system will automatically request dataset build and retrain model
VERSION_MISMATCH_RETRAINING_INTERVAL_HOURS=24

# Training period length in days for dataset building (default: 30 days)
# Number of days of historical data to use for training split
MODEL_RETRAINING_TRAIN_PERIOD_DAYS=30

# Validation period length in days for dataset building (default: 7 days)
# Number of days of historical data to use for validation split
MODEL_RETRAINING_VALIDATION_PERIOD_DAYS=7

# Test period length in days for dataset building (default: 1 day)
# Number of days of historical data to use for test split
MODEL_RETRAINING_TEST_PERIOD_DAYS=1

# Prediction horizon in seconds for model training (default: 60 seconds = 1 minute)
# This determines how far into the future the model predicts price movements
# Prediction horizon in seconds (default: 180 = 3 minutes)
# Increased from 60s to 180s to allow more time for market movements
# This reduces zero targets and duplicates in datasets
MODEL_PREDICTION_HORIZON_SECONDS=180

# Classification threshold for target computation (default: 0.005 = 0.5%)
# Price movement must exceed this threshold to be classified as 'up' or 'down'
# Values below threshold are classified as 'flat'
MODEL_CLASSIFICATION_THRESHOLD=0.005

# Regression Threshold Configuration (for converting predicted return to BUY/SELL/HOLD signal)
# Threshold for regression models: if predicted_return > threshold: BUY, if < -threshold: SELL, else: HOLD
# Default: 0.001 (0.1%)
MODEL_REGRESSION_THRESHOLD=0.001

# Classification Probability Difference Threshold (hysteresis for BUY/SELL signals)
# Minimum difference between buy_probability and sell_probability required to generate a signal.
# If |buy_probability - sell_probability| < min_probability_diff, signal is HOLD (None).
# This provides hysteresis to prevent signals when model is uncertain.
# INVARIANT: This check applies BEFORE confidence threshold - if difference is too small, signal is HOLD regardless of confidence.
# Only applies to classification models without calibrated thresholds.
# Default: 0.05 (5%)
MODEL_MIN_PROBABILITY_DIFF=0.05

# Maximum expected return for confidence calculation in regression models (used to normalize confidence 0-1)
# Default: 0.01 (1%)
MODEL_REGRESSION_MAX_EXPECTED_RETURN=0.01

# Prediction Threshold Configuration (for improving recall of minority classes)
# These thresholds are applied to class probabilities instead of using argmax
# If probability for a class exceeds its threshold, that class is predicted
# If multiple classes exceed thresholds, the one with highest probability is chosen
# If no class exceeds threshold, falls back to argmax
# Set to None to use argmax (default behavior)
MODEL_PREDICTION_USE_THRESHOLD_CALIBRATION=false
MODEL_PREDICTION_THRESHOLD_CLASS_0=
MODEL_PREDICTION_THRESHOLD_CLASS_1=
MODEL_PREDICTION_THRESHOLD_CLASS_NEG1=

# Dataset Quality Control Configuration
# Maximum ratio of NaN values per feature column (0.0-1.0, default: 0.5 = 50%)
# Features with NaN ratio above this threshold will be logged as warnings
DATASET_MAX_FEATURE_NAN_RATIO=0.5

# Maximum ratio of NaN values per row across all features (0.0-1.0, default: 0.8 = 80%)
# Rows with NaN ratio above this threshold will be dropped from dataset
DATASET_MAX_ROW_NAN_RATIO=0.8

# Minimum ratio of valid (non-NaN) features per row (0.0-1.0, default: 0.3 = 30%)
# Rows with valid features ratio below this threshold will be dropped from dataset
DATASET_MIN_VALID_FEATURES_RATIO=0.3

# Fail dataset build if any feature has NaN ratio above threshold (default: false)
# If true, dataset build will fail when features exceed DATASET_MAX_FEATURE_NAN_RATIO
# If false, only warnings will be logged and problematic features will be kept
DATASET_FAIL_ON_HIGH_NAN_RATIO=false

# =============================================================================
# Dataset Building Cache Configuration
# =============================================================================
# Enable caching for dataset building (default: true)
# Uses Redis if available, falls back to memory cache automatically
# Cache significantly speeds up repeated dataset builds (10-30x speedup for full cache hits)
DATASET_BUILDER_CACHE_ENABLED=true

# Enable historical data caching (default: true)
# Caches DataFrame's historical data in Redis (primary) or memory (fallback)
# TTL: 24 hours (data may be updated via backfill)
DATASET_BUILDER_CACHE_HISTORICAL_DATA_ENABLED=true
CACHE_TTL_HISTORICAL_DATA_SECONDS=86400  # 24 hours

# Enable computed features caching (default: true)
# Caches FeatureVector for each timestamp in Redis (primary) or memory (fallback)
# TTL: 7 days (features are more stable than raw data)
DATASET_BUILDER_CACHE_FEATURES_ENABLED=true
CACHE_TTL_FEATURES_SECONDS=604800  # 7 days

# Memory fallback cache limits (only used when Redis unavailable)
# Maximum cache size in MB for memory fallback cache (default: 1024 = 1GB)
# Redis uses maxmemory setting from Redis configuration (default: 2GB)
CACHE_MAX_SIZE_MB=1024
# Maximum number of cache entries for memory fallback cache (default: 10000)
# Redis uses maxmemory-policy from Redis configuration (default: allkeys-lru)
CACHE_MAX_ENTRIES=10000

# Cache invalidation settings
# Automatically invalidate cache when Feature Registry version changes (default: true)
# Works for both Redis and memory cache
CACHE_INVALIDATION_ON_REGISTRY_CHANGE=true
# Automatically invalidate cache when historical data files are modified (default: true)
# Works for both Redis and memory cache
CACHE_INVALIDATION_ON_DATA_CHANGE=true

# =============================================================================
# Dataset Builder Configuration
# =============================================================================
# Batch size for processing timestamps in dataset builder (default: 1000)
# Larger batches improve performance but use more memory
# Recommended values:
# - Small datasets (< 1 day): 500-1000
# - Medium datasets (1-7 days): 1000-2000
# - Large datasets (> 7 days): 2000-5000
DATASET_BUILDER_BATCH_SIZE=1000

# =============================================================================
# Target Computation Configuration (feature-service)
# =============================================================================
# Maximum expected delay for data ingestion in seconds (default: 30)
# Used to determine if data is too old for target computation
TARGET_COMPUTATION_MAX_EXPECTED_DELAY_SECONDS=30

# Maximum lookback window for data availability fallback in seconds (default: 300)
# Used when target_timestamp is not available, how far back to look for data
TARGET_COMPUTATION_MAX_LOOKBACK_SECONDS=300

# Buffer window for loading historical data in seconds (default: 60)
# Adds buffer around prediction_timestamp and target_timestamp when loading data
TARGET_COMPUTATION_DATA_BUFFER_SECONDS=60

# =============================================================================
# DEPRECATED: Execution Events Buffer Configuration (for backward compatibility)
# =============================================================================
# NOTE: These variables are deprecated for training pipeline (which now uses
# market-data-only training via Feature Service). They may still be used for
# quality monitoring or other purposes. Will be removed in future versions.

# Enable persistent buffer for training orchestrator so that unused execution
# events can be recovered from database after service restart.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_PERSISTENCE_ENABLED=true

# Enable automatic buffer recovery on startup. When enabled, the service will
# load execution events that have not yet been used for training into the
# in-memory buffer on startup.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_RECOVERY_ON_STARTUP=true

# Maximum number of execution events to recover on startup.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_MAX_RECOVERY_EVENTS=10000

# Enable training queue to avoid cancelling in-progress training when new data
# arrives. New training requests are queued and processed sequentially.
TRAINING_QUEUE_ENABLED=true

# Maximum size of the training queue (number of pending training requests).
TRAINING_QUEUE_MAX_SIZE=10

# Allow CRITICAL priority retraining (e.g., severe quality degradation) to
# cancel the current training when enabled. Default is false.
TRAINING_FORCE_CANCEL_ON_CRITICAL=false

# Maximum number of parallel training tasks allowed (per service instance).
# Current implementation runs trainings sequentially but this value is reserved
# for future parallelization support.
MAX_PARALLEL_TRAINING=1

# Interval in seconds for batch buffer update operations in the training
# orchestrator. Used to reduce write frequency when persisting buffer state.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BATCH_BUFFER_UPDATE_INTERVAL_SECONDS=10

# =============================================================================
# Signal Generation Configuration
# =============================================================================
# Rate limit for signal generation (signals per minute)
SIGNAL_GENERATION_RATE_LIMIT=60

# Burst allowance for rate limiting (additional signals allowed in burst)
SIGNAL_GENERATION_BURST_ALLOWANCE=10

# Skip signal generation if open order exists for same asset and strategy
# Set to 'true' to prevent duplicate orders, 'false' to allow multiple signals
SIGNAL_GENERATION_SKIP_IF_OPEN_ORDER=true

# Check only opposite direction orders when skipping (e.g., skip buy signal if sell order exists)
# Set to 'true' to check only opposite direction orders, 'false' to check all orders
# Only used when SIGNAL_GENERATION_SKIP_IF_OPEN_ORDER=true
SIGNAL_GENERATION_CHECK_OPPOSITE_ORDERS_ONLY=false

# Enable warm-up mode when no trained model exists
WARMUP_MODE_ENABLED=true

# Warm-up signal generation frequency (signals per minute)
WARMUP_SIGNAL_FREQUENCY=1

# Minimum order amount for warm-up signals (in quote currency)
WARMUP_MIN_AMOUNT=100.0

# Maximum order amount for warm-up signals (in quote currency)
WARMUP_MAX_AMOUNT=1000.0

# Randomness level for warm-up signals (0.0 = deterministic, 1.0 = fully random)
WARMUP_RANDOMNESS_LEVEL=0.5

# Intelligent Mode Configuration
# Intelligent signal generation frequency (signals per minute) for model-based signals.
# Recommendation for target horizon 1800s (30 minutes):
#   - 0.05  => 1 signal / 20 minutes (консервативно)
#   - 0.067 => 1 signal / 15 minutes (чуть агрессивнее)
# If not set, defaults to 60 (1 signal per second) – в проде явно задайте более низкое значение.
INTELLIGENT_SIGNAL_FREQUENCY=0.05

# Safety margin for balance adaptation (portion of available balance that can be used, 0.0-1.0]
# Example: 0.95 means use up to 95% of available balance when adapting amounts
BALANCE_ADAPTATION_SAFETY_MARGIN=0.95

# Maximum acceptable age of balance data (in seconds). Older balance snapshots are treated as stale
# and will cause signal generation to skip due to unreliable balance information.
BALANCE_DATA_MAX_AGE_SECONDS=60

# Maximum acceptable age of cached market data (in seconds). If market data is older than this
# value, signal generation will treat it as stale and skip to avoid decisions on outdated prices.
MARKET_DATA_MAX_AGE_SECONDS=60

# Warning threshold for cached market data staleness (in seconds). When market data age is above
# this value but below MARKET_DATA_MAX_AGE_SECONDS, warnings are logged but data is still used.
MARKET_DATA_STALE_WARNING_THRESHOLD_SECONDS=30

# Alert threshold for signal processing delay (in seconds). When the time between signal creation
# and publication exceeds this threshold, a warning is logged and metrics are updated for monitoring.
SIGNAL_PROCESSING_DELAY_ALERT_THRESHOLD_SECONDS=300

# Target Evaluation Configuration
TARGET_EVALUATION_BASE_INTERVAL_SECONDS=10
TARGET_EVALUATION_MIN_INTERVAL_SECONDS=5
TARGET_EVALUATION_MAX_INTERVAL_SECONDS=60
# Age in days to mark targets as obsolete (stop processing attempts)
TARGET_EVALUATION_OBSOLETE_AGE_DAYS=3

# Maximum lookback window for target computation data availability fallback (seconds)
# Used when requesting actual target values from feature-service
# Default: 300 (5 minutes)
FEATURE_SERVICE_TARGET_COMPUTATION_MAX_LOOKBACK_SECONDS=300

# Enable on-demand balance sync via ws-gateway when model-service detects that balance
# snapshots in the account_balances table are stale or missing. When enabled, the
# model-service will call ws-gateway /api/v1/balances/sync before re-reading the table.
BALANCE_SYNC_ENABLED=true

# Minimum interval (in seconds) between successive balance sync requests from model-service.
# This protects ws-gateway and Bybit API from being spammed when multiple signals are generated.
BALANCE_SYNC_MIN_INTERVAL_SECONDS=30

# Timeout (in seconds) for HTTP requests from model-service to ws-gateway balance sync endpoint.
BALANCE_SYNC_TIMEOUT_SECONDS=5.0

# Risk Management Configuration for Model Service
# =============================================================================
# Take profit threshold (as percentage of unrealized PnL)
# NOTE: This variable is used ONLY by exit strategy evaluator in model-service.
# It is NOT used by intelligent_signal_generator (take profit logic was moved to order-manager).
# 
# RECOMMENDATION: Use ORDERMANAGER_EXIT_TP_THRESHOLD_PCT instead (see Order Manager section).
# This variable is kept for backward compatibility with model-service exit strategy.
# To disable model-service exit strategy, set EXIT_STRATEGY_ENABLED=false below.
MODEL_SERVICE_TAKE_PROFIT_PCT=3.0

# Maximum position size ratio (0.0-1.0) for portfolio diversification
# This is a normalized ratio relative to total portfolio exposure
# Currently not used - see ORDERMANAGER_MAX_POSITION_SIZE for absolute limit
MODEL_SERVICE_MAX_POSITION_SIZE_RATIO=0.8

# =============================================================================
# Exit Strategy Configuration (Model Service)
# =============================================================================
# Enable position-based exit strategy evaluation in model-service
# 
# NOTE: This feature generates exit signals based on position updates via RabbitMQ events.
# It has been SUPERSEDED by order-manager exit rules (ORDERMANAGER_EXIT_TP_ENABLED, etc.)
# which are faster and simpler (check PnL directly when processing signals).
#
# RECOMMENDATION: Set to 'false' and use ORDERMANAGER_EXIT_TP_ENABLED instead.
# Model-service exit strategy adds latency (event → model-service → signal → order-manager → order)
# while order-manager exit rules check PnL synchronously during signal processing.
#
# Keep enabled only if you need:
# - Complex exit rules (trailing stop, time-based exit) that are not in order-manager
# - Event-driven exit signals independent of trading signals
EXIT_STRATEGY_ENABLED=false

# Rate limit for exit signal generation (signals per asset per minute)
EXIT_STRATEGY_RATE_LIMIT=10

# Take Profit Configuration (Model Service Exit Strategy)
# NOTE: These settings are used ONLY when EXIT_STRATEGY_ENABLED=true above.
# Threshold uses MODEL_SERVICE_TAKE_PROFIT_PCT (see above).
# 
# RECOMMENDATION: Use ORDERMANAGER_EXIT_TP_ENABLED instead (see Order Manager section).
TAKE_PROFIT_ENABLED=true
TAKE_PROFIT_PARTIAL_EXIT=false
TAKE_PROFIT_PARTIAL_AMOUNT_PCT=50.0

# Stop Loss Configuration (Model Service Exit Strategy)
# NOTE: These settings are used ONLY when EXIT_STRATEGY_ENABLED=true above.
# 
# RECOMMENDATION: Use ORDERMANAGER_EXIT_SL_ENABLED instead (see Order Manager section).
STOP_LOSS_ENABLED=true
STOP_LOSS_THRESHOLD_PCT=-2.0

# Trailing Stop Configuration (local trailing stop is deprecated; use exchange trailing stop in order-manager)
# These settings are kept for backward compatibility but are not used in new deployments.
TRAILING_STOP_ENABLED=false
TRAILING_STOP_ACTIVATION_PCT=2.0
TRAILING_STOP_DISTANCE_PCT=1.0

# Time-Based Exit Configuration
TIME_BASED_EXIT_ENABLED=false
TIME_BASED_EXIT_MAX_HOURS=24
TIME_BASED_EXIT_PROFIT_TARGET_PCT=1.0

# =============================================================================
# Trading Strategy Configuration
# =============================================================================
# Comma-separated list of trading strategy identifiers
# Example: momentum_v1,mean_reversion_v1
TRADING_STRATEGIES=

# =============================================================================
# Order Manager Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4600)
ORDERMANAGER_PORT=4600

# API key for REST API authentication
# Other microservices use this key to authenticate with Order Manager
ORDERMANAGER_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
ORDERMANAGER_LOG_LEVEL=INFO

# Service identifier
ORDERMANAGER_SERVICE_NAME=order-manager

# =============================================================================
# Order Execution Configuration
# =============================================================================
# Enable dry-run mode (process signals but do not send orders to Bybit)
# Set to 'true' for testing without real orders
ORDERMANAGER_ENABLE_DRY_RUN=false

# Maximum order size for single order (in USDT)
# Orders exceeding this size may be split if order splitting is enabled
# NOTE: This parameter is defined but NOT currently used in code checks.
# Real validation uses: MAX_EXPOSURE × MAX_ORDER_SIZE_RATIO
# Keeping it for future use or documentation purposes
ORDERMANAGER_MAX_SINGLE_ORDER_SIZE=500.0

# Enable order splitting for large amounts
# When enabled, large orders are split into multiple smaller orders
ORDERMANAGER_ENABLE_ORDER_SPLITTING=false

# Timeout for order creation API calls (in seconds)
ORDERMANAGER_ORDER_EXECUTION_TIMEOUT=30

# =============================================================================
# Risk Limits Configuration
# =============================================================================
# Maximum position size per asset (in base currency)
# Note: Should accommodate existing positions (e.g., 1.19 ETH), so set to 2.0 to allow reasonable position sizes
ORDERMANAGER_MAX_POSITION_SIZE=2.0

# Maximum total exposure across all positions (in USDT)
# Used in combination with MAX_ORDER_SIZE_RATIO to calculate max order size
# Max order size = MAX_EXPOSURE × MAX_ORDER_SIZE_RATIO = 10000 × 0.1 = 1000 USDT
ORDERMANAGER_MAX_EXPOSURE=10000.0

# Maximum order size as ratio of maximum exposure (0.0 to 1.0)
# Example: 0.1 means maximum 10% of MAX_EXPOSURE per order
# Max order size = 10000 × 0.1 = 1000 USDT (to limit orders to $1000 equivalent)
ORDERMANAGER_MAX_ORDER_SIZE_RATIO=0.1

# =============================================================================
# Bybit API Retry Configuration
# =============================================================================
# Maximum retry attempts for Bybit API calls
ORDERMANAGER_BYBIT_API_RETRY_MAX_ATTEMPTS=3

# Base delay for exponential backoff (in seconds)
ORDERMANAGER_BYBIT_API_RETRY_BASE_DELAY=1.0

# Maximum delay between retries (in seconds)
ORDERMANAGER_BYBIT_API_RETRY_MAX_DELAY=30.0

# Exponential backoff multiplier
ORDERMANAGER_BYBIT_API_RETRY_MULTIPLIER=2.0

# =============================================================================
# Order Type Selection Configuration
# =============================================================================
# Confidence threshold for market orders (0.0 to 1.0)
# Signals with confidence above this threshold may use market orders
ORDERMANAGER_MARKET_ORDER_CONFIDENCE_THRESHOLD=0.9

# Spread threshold for market orders (as percentage)
# Market orders may be used when spread is below this threshold
ORDERMANAGER_MARKET_ORDER_SPREAD_THRESHOLD=0.1

# Price offset ratio for limit orders (0.0 to 1.0)
# Used to calculate limit price offset from market price
ORDERMANAGER_LIMIT_ORDER_PRICE_OFFSET_RATIO=0.5

# =============================================================================
# Position Management Configuration
# =============================================================================
# Interval for position snapshots (in seconds)
# Position state is periodically snapshotted for historical tracking
ORDERMANAGER_POSITION_SNAPSHOT_INTERVAL=300

# Interval for position validation (in seconds)
# Position state is validated against computed position from order history
ORDERMANAGER_POSITION_VALIDATION_INTERVAL=3600

# =============================================================================
# Pending Order Cancellation Configuration
# =============================================================================
# Timeout in minutes after which pending orders will be automatically cancelled
# Pending orders that exceed this timeout are considered stale and will be cancelled
# to prevent orders from hanging indefinitely
ORDERMANAGER_PENDING_ORDER_TIMEOUT_MINUTES=5

# Interval in seconds for checking pending orders that exceed timeout
# The task runs periodically to find and cancel stale pending orders
ORDERMANAGER_PENDING_ORDER_CHECK_INTERVAL=60

# =============================================================================
# Order Cancellation Configuration
# =============================================================================
# If true, only cancel orders with opposite direction (buy vs sell)
# If false, cancel all pending orders for same asset when new signal arrives
ORDERMANAGER_CANCEL_OPPOSITE_ORDERS_ONLY=false

# Automatically cancel orders older than this timeout (in seconds)
# Set to 0 to disable automatic cancellation of stale orders
ORDERMANAGER_CANCEL_STALE_ORDER_TIMEOUT=3600

# =============================================================================
# Risk Management Configuration
# =============================================================================
# Unrealized loss warning threshold (as percentage)
# Warning is logged when position unrealized loss exceeds this threshold
ORDERMANAGER_UNREALIZED_LOSS_WARNING_THRESHOLD=10.0

# Enable balance check before order creation (default: true)
# If false, balance validation is skipped - Bybit API will reject orders with insufficient balance anyway.
# Setting to false reduces API calls and improves performance, but loses early rejection and detailed logging.
ORDERMANAGER_ENABLE_BALANCE_CHECK=true

# Enable automatic order size reduction when insufficient balance error (110007) occurs (default: true)
# If true, system will try to reduce order size based on available balance and retry order creation.
# If false, orders will be immediately rejected when 110007 error occurs.
ORDERMANAGER_ENABLE_ORDER_SIZE_REDUCTION=true

# =============================================================================
# Take Profit / Stop Loss Configuration (Bybit Exchange Orders)
# =============================================================================
# Enable TP/SL order creation on Bybit (default: true)
# If True, take profit and stop loss orders will be created together with main order
# 
# NOTE: This creates CONDITIONAL ORDERS on Bybit exchange (price-based triggers).
# This is DIFFERENT from ORDERMANAGER_EXIT_TP_ENABLED above (PnL-based checks).
#
# Differences:
# - ORDERMANAGER_TP_THRESHOLD_PCT: Creates conditional TP order on exchange (closes when PRICE reaches level)
# - ORDERMANAGER_EXIT_TP_THRESHOLD_PCT: Checks unrealized PnL and generates close signal (closes when PnL reaches level)
#
# You can use both mechanisms:
# - Exchange TP/SL orders: Fast, automatic, but price-based (may not match exact PnL due to fees/slippage)
# - Exit rules: PnL-based, more accurate, but requires signal processing
ORDERMANAGER_TP_SL_ENABLED=true

# Take Profit Configuration (Exchange Orders)
# Enable take profit orders on Bybit exchange (default: true)
ORDERMANAGER_TP_ENABLED=true
# TP threshold as percentage (default: 3.0%)
# For buy orders: TP = entry_price * (1 + threshold/100)
# For sell orders: TP = entry_price * (1 - threshold/100)
# 
# NOTE: This is price-based, not PnL-based. For PnL-based exit, use ORDERMANAGER_EXIT_TP_THRESHOLD_PCT above.
ORDERMANAGER_TP_THRESHOLD_PCT=3.0

# Stop Loss Configuration (Exchange Orders)
# Enable stop loss orders on Bybit exchange (default: true)
ORDERMANAGER_SL_ENABLED=true
# SL threshold as percentage (default: -2.0%)
# For buy orders: SL = entry_price * (1 - abs(threshold)/100)
# For sell orders: SL = entry_price * (1 + abs(threshold)/100)
#
# NOTE: This is price-based, not PnL-based. For PnL-based exit, use ORDERMANAGER_EXIT_SL_THRESHOLD_PCT above.
ORDERMANAGER_SL_THRESHOLD_PCT=-2.0

# Priority for TP/SL calculation (default: metadata)
# Options: 'metadata' (use signal.metadata if available), 'settings' (use .env values), 'both' (try metadata first, fallback to settings)
ORDERMANAGER_TP_SL_PRIORITY=metadata

# TP/SL trigger method (default: LastPrice)
# Options: 'LastPrice', 'IndexPrice', 'MarkPrice'
ORDERMANAGER_TP_SL_TRIGGER_BY=LastPrice

# =============================================================================
# Take Profit / Stop Loss Position Exit Configuration (RECOMMENDED)
# =============================================================================
# Enable take profit exit rule (default: true)
# If True, positions will be closed when unrealized PnL exceeds threshold
# 
# This is the RECOMMENDED mechanism for take profit/stop loss management.
# It checks PnL synchronously when processing any signal, ensuring positions are
# closed before new orders are created. Faster and simpler than model-service exit strategy.
#
# NOTE: This is DIFFERENT from ORDERMANAGER_TP_THRESHOLD_PCT below:
# - ORDERMANAGER_TP_THRESHOLD_PCT: Creates conditional TP orders on Bybit exchange (price-based)
# - ORDERMANAGER_EXIT_TP_THRESHOLD_PCT: Checks unrealized PnL and generates close signal (PnL-based)
# 
# You can use both mechanisms simultaneously for redundancy, or use only one.
ORDERMANAGER_EXIT_TP_ENABLED=true

# Take profit exit threshold as percentage (default: 3.0%)
# Position will be closed when unrealized PnL percentage exceeds this value
# Example: 3.0 means close position when unrealized profit >= 3%
ORDERMANAGER_EXIT_TP_THRESHOLD_PCT=3.0

# Enable stop loss exit rule (default: true)
# If True, positions will be closed when unrealized PnL falls below threshold
# 
# This is the RECOMMENDED mechanism for stop loss management.
# It checks PnL synchronously when processing any signal, ensuring positions are
# closed before losses exceed threshold.
#
# NOTE: This is DIFFERENT from ORDERMANAGER_SL_THRESHOLD_PCT below:
# - ORDERMANAGER_SL_THRESHOLD_PCT: Creates conditional SL orders on Bybit exchange (price-based)
# - ORDERMANAGER_EXIT_SL_THRESHOLD_PCT: Checks unrealized PnL and generates close signal (PnL-based)
ORDERMANAGER_EXIT_SL_ENABLED=true

# Stop loss exit threshold as percentage (negative value, default: -2.0%)
# Position will be closed when unrealized PnL percentage falls below this value
# Example: -2.0 means close position when unrealized loss <= -2%
ORDERMANAGER_EXIT_SL_THRESHOLD_PCT=-2.0

# Exchange Trailing Stop Configuration (Bybit Set Trading Stop)
# Enable exchange-level trailing stop via Bybit Set Trading Stop API.
# When enabled, order-manager will set trailingStop/activePrice on positions after entry.
ORDERMANAGER_EXCHANGE_TRAILING_STOP_ENABLED=false

# Trailing stop activation threshold as percentage of entry price.
# For long positions: activePrice ~= entry_price * (1 + pct/100).
ORDERMANAGER_TRAILING_STOP_ACTIVATION_PCT=2.0

# Trailing stop distance as percentage of entry price.
# Absolute trailingStop value is derived as entry_price * pct/100.
ORDERMANAGER_TRAILING_STOP_DISTANCE_PCT=1.0

# Which side to apply trailing stop to: LONG, SHORT, or BOTH. Default: LONG.
ORDERMANAGER_TRAILING_STOP_APPLY_TO_SIDE=LONG

# Enable closing position before processing opposite signal.
# When enabled, if opposite signal arrives (e.g., SELL when long position exists),
# position will be closed first, then new order will be created.
ORDERMANAGER_CLOSE_POSITION_BEFORE_OPPOSITE_SIGNAL=true

# Timeout in seconds for waiting position closure before proceeding with new order.
# Used only if ORDERMANAGER_POSITION_CLOSE_WAIT_MODE is 'polling'.
ORDERMANAGER_POSITION_CLOSE_TIMEOUT_SECONDS=30

# Mode for waiting position closure: 'polling' (check position status with timeout),
# 'websocket' (wait for WebSocket events, not implemented yet),
# 'none' (create close order and immediately proceed with new order).
ORDERMANAGER_POSITION_CLOSE_WAIT_MODE=none

# Minimum position size to consider for closing.
# Positions smaller than this threshold will be ignored.
ORDERMANAGER_POSITION_CLOSE_MIN_SIZE_THRESHOLD=0.00000001

# Maximum age of position data in seconds before considering it stale.
# If position.last_updated is older than this, system will fetch fresh data from Bybit.
ORDERMANAGER_POSITION_MAX_AGE_SECONDS=60

# Enable fallback to direct Bybit API for position data when Position Manager data is stale or unavailable.
ORDERMANAGER_ENABLE_BYBIT_POSITION_FALLBACK=true

# Automatically trigger Position Manager sync-bybit API (fire-and-forget) after fetching position directly from Bybit.
# This updates Position Manager database with fresh data to fix discrepancies.
ORDERMANAGER_AUTO_SYNC_POSITION_AFTER_BYBIT_FETCH=true

# =============================================================================
# Position Manager Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4800)
POSITION_MANAGER_PORT=4800

# API key for REST API authentication
# Other microservices use this key to authenticate with Position Manager
POSITION_MANAGER_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
POSITION_MANAGER_LOG_LEVEL=INFO

# Service identifier
POSITION_MANAGER_SERVICE_NAME=position-manager

# =============================================================================
# Position Management Configuration
# =============================================================================
# Interval for position snapshots (in seconds)
# Position state is periodically snapshotted for historical tracking
POSITION_MANAGER_SNAPSHOT_INTERVAL=3600  # 1 hour

# Retention period for position snapshots (in days)
# Snapshots older than this period are automatically deleted
POSITION_MANAGER_SNAPSHOT_RETENTION_DAYS=365

# Interval for position validation (in seconds)
# Position state is validated against authoritative sources
POSITION_MANAGER_VALIDATION_INTERVAL=1800  # 30 minutes

# Interval for Bybit position synchronization (in seconds)
# Periodic sync with Bybit API to detect and fix discrepancies
POSITION_MANAGER_BYBIT_SYNC_INTERVAL=3600  # 1 hour

# Portfolio metrics cache TTL (in seconds)
# Metrics are cached in memory and invalidated on position updates
POSITION_MANAGER_METRICS_CACHE_TTL=10

# =============================================================================
# Position Update Strategy Configuration
# =============================================================================
# Use WebSocket average price for position updates
# If true, WebSocket avgPrice is used when difference exceeds threshold
POSITION_MANAGER_USE_WS_AVG_PRICE=true

# Average price difference threshold (as ratio, e.g., 0.001 = 0.1%)
# WebSocket avgPrice is used if difference from existing value exceeds this threshold
POSITION_MANAGER_AVG_PRICE_DIFF_THRESHOLD=0.001  # 0.1%

# Position size validation threshold (as ratio)
# Size discrepancies exceeding this threshold trigger validation
POSITION_MANAGER_SIZE_VALIDATION_THRESHOLD=0.0001

# Price staleness threshold (in seconds)
# External API is queried if price is older than this threshold
POSITION_MANAGER_PRICE_STALENESS_THRESHOLD=300  # 5 minutes

# External price API timeout (in seconds)
POSITION_MANAGER_PRICE_API_TIMEOUT=5

# External price API retry attempts
POSITION_MANAGER_PRICE_API_RETRIES=3

# Optimistic locking retry attempts
# Number of retries when version conflict occurs during position update
POSITION_MANAGER_OPTIMISTIC_LOCK_RETRIES=3

# Optimistic locking backoff base delay (in milliseconds)
# Exponential backoff starts from this value (100ms, 200ms, 400ms)
POSITION_MANAGER_OPTIMISTIC_LOCK_BACKOFF_BASE=100

# Enable timestamp-based size conflict resolution between WebSocket and Order Manager
# When enabled, WebSocket size may update DB size if its event timestamp is fresher
POSITION_MANAGER_ENABLE_TIMESTAMP_RESOLUTION=true

# Optional tolerance window (in seconds) when comparing timestamps
# WebSocket timestamp must be greater than (order_timestamp + tolerance) to win
POSITION_MANAGER_TIMESTAMP_TOLERANCE_SECONDS=0

# =============================================================================
# Rate Limiting Configuration
# =============================================================================
# Enable rate limiting for API endpoints
POSITION_MANAGER_RATE_LIMIT_ENABLED=true

# Default rate limit (requests per minute)
# Applied to all API keys unless overridden
POSITION_MANAGER_RATE_LIMIT_DEFAULT=100

# Rate limit overrides per API key (comma-separated key:limit pairs)
# Example: model-service-key:100,risk-manager-key:200,ui-key:1000
POSITION_MANAGER_RATE_LIMIT_OVERRIDES=model-service-key:100,risk-manager-key:200,ui-key:1000

# =============================================================================
# Grafana Monitoring Service Configuration
# =============================================================================
# Grafana UI port (non-standard port starting from 4700)
GRAFANA_PORT=4700

# Grafana admin user credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=XXXX

# Grafana PostgreSQL read-only user credentials
# This user is created by migration and has SELECT permissions on monitoring tables
GRAFANA_POSTGRES_USER=grafana_monitor
GRAFANA_POSTGRES_PASSWORD=XXXX

# =============================================================================
# Graylog Configuration
# =============================================================================
# Graylog Web UI port (non-standard port starting from 4701)
GRAYLOG_WEB_PORT=4701

# Graylog GELF UDP port for receiving logs (internal, not exposed)
GRAYLOG_GELF_PORT=4711

# Graylog password secret (generate with: openssl rand -base64 32)
# Used for encrypting sensitive data in Graylog
GRAYLOG_PASSWORD_SECRET=XXXX

# Graylog root user password (plain text, for initial setup and API access)
# WARNING: Change this in production!
# Required for creating inputs via API
GRAYLOG_ROOT_PASSWORD=XXXX

# Graylog root user password SHA256 hash (generate with: echo -n "password" | sha256sum | awk '{print $1}')
# Used for authentication in Graylog
# Generate: echo -n "your_password" | sha256sum | awk '{print $1}'
GRAYLOG_ROOT_PASSWORD_SHA2=XXXX

# =============================================================================
# Kibana Configuration (read-only analytics for Graylog Elasticsearch indices)
# =============================================================================
# Kibana Web UI port (non-standard port starting from 4704)
# Exposed only on localhost by default in docker-compose.yml
KIBANA_PORT=4704

# =============================================================================
# Trading Events Forwarder Configuration
# =============================================================================
# RabbitMQ exchange name for trading events (all services publish here)
RABBITMQ_TRADING_EVENTS_EXCHANGE=trading_events

# RabbitMQ queue name used by trading-events-forwarder (owned by forwarder)
RABBITMQ_TRADING_EVENTS_QUEUE=trading_events_forwarder

# Graylog host for custom events GELF input (internal Docker hostname)
GRAYLOG_HOST=graylog

# Graylog GELF UDP port for custom trading events (separate from main GELF logs)
# Must match port of dedicated GELF UDP input in Graylog (e.g. 4712)
GRAYLOG_CUSTOM_EVENTS_GELF_PORT=4712

# Trading events forwarder service metadata
TRADING_EVENTS_FORWARDER_SERVICE_NAME=trading-events-forwarder
TRADING_EVENTS_FORWARDER_LOG_LEVEL=INFO

# =============================================================================
# Fluent Bit Configuration
# =============================================================================
# Fluent Bit log level (debug, info, warn, error)
FLUENT_BIT_LOG_LEVEL=info

# Fluent Bit HTTP API port for metrics and health checks (internal)
FLUENT_BIT_HTTP_PORT=2020

# Path to Docker containers logs directory on host
# Default: /mnt/docker/containers (non-standard path)
# Standard path would be: /var/lib/docker/containers
DOCKER_CONTAINERS_PATH=/mnt/docker/containers

# Environment name for log enrichment (optional)
ENVIRONMENT=production

# =============================================================================
# Dashboard API Configuration
# =============================================================================
# REST API port (non-standard port starting from 4050)
DASHBOARD_API_PORT=4050

# API key for REST API authentication
DASHBOARD_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
DASHBOARD_API_LOG_LEVEL=INFO

# Service identifier
DASHBOARD_API_SERVICE_NAME=dashboard-api

# =============================================================================
# Dashboard Frontend Configuration
# =============================================================================
# Frontend port (non-standard port starting from 4051)
DASHBOARD_FRONTEND_PORT=4051
