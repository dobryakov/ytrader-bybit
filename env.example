# =============================================================================
# Bybit API Configuration
# =============================================================================
# Bybit API credentials for WebSocket authentication and REST API (optional for public endpoints)
# Use testnet for development, mainnet for production
# Note: API keys are optional for public market data endpoints (used by backfilling service)
BYBIT_API_KEY=XXXX
BYBIT_API_SECRET=XXXX
BYBIT_ENVIRONMENT=testnet  # or 'mainnet' for production

# =============================================================================
# Database Configuration (PostgreSQL)
# =============================================================================
# Shared PostgreSQL database for all microservices
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=XXXX
POSTGRES_USER=XXXX
POSTGRES_PASSWORD=XXXX

# =============================================================================
# RabbitMQ Configuration
# =============================================================================
# Message broker for event-driven communication
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=XXXX
RABBITMQ_PASSWORD=XXXX

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis for distributed locking (used by order-manager)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=

# =============================================================================
# WebSocket Gateway Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4400)
WS_GATEWAY_PORT=4400

# WebSocket Gateway hostname (for model-service to subscribe to channels)
WS_GATEWAY_HOST=ws-gateway

# API key for REST API authentication
# Other microservices use this key to manage subscriptions
WS_GATEWAY_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
WS_GATEWAY_LOG_LEVEL=INFO

# Service identifier
WS_GATEWAY_SERVICE_NAME=ws-gateway

# WebSocket connection strategy: 'dual' (separate public/private connections) or 'single' (one private connection for all)
# Default: 'dual' - recommended for better scalability and separation of concerns
# 'single' mode uses only private endpoint for backward compatibility
BYBIT_WS_STRATEGY=dual  # or 'single'

# Bybit public WebSocket category: 'spot', 'linear', 'inverse', 'option', 'spread'
# Default: 'linear' for unified trading (USDT/USDC perpetual & futures)
# Use 'spot' for spot trading, 'linear' for unified trading
BYBIT_WS_PUBLIC_CATEGORY=linear  # or 'spot', 'inverse', 'option', 'spread'

# =============================================================================
# Model Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4500)
MODEL_SERVICE_PORT=4500

# API key for REST API authentication
# Other microservices use this key to authenticate with Model Service
MODEL_SERVICE_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
MODEL_SERVICE_LOG_LEVEL=INFO

# Service identifier
MODEL_SERVICE_SERVICE_NAME=model-service

# =============================================================================
# Feature Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4900)
FEATURE_SERVICE_PORT=4900

# Feature Service hostname (for REST API calls and model-service to connect)
FEATURE_SERVICE_HOST=feature-service

# API key for REST API authentication
# Other microservices use this key to authenticate with Feature Service
FEATURE_SERVICE_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
FEATURE_SERVICE_LOG_LEVEL=INFO

# Service identifier
FEATURE_SERVICE_SERVICE_NAME=feature-service

# Enable queue subscription for real-time features (true) or use REST API polling (false)
# Default: true - use RabbitMQ queue 'features.live' for real-time features
FEATURE_SERVICE_USE_QUEUE=true

# Feature cache TTL in seconds for real-time feature vectors
# Features older than this value are considered stale
FEATURE_SERVICE_FEATURE_CACHE_TTL_SECONDS=30

# Maximum wait time in seconds for dataset building request (default: 1 hour)
FEATURE_SERVICE_DATASET_BUILD_TIMEOUT_SECONDS=3600

# Timeout in seconds for getting dataset metadata from Feature Service API (default: 60 seconds)
# Increase if you experience timeout errors when fetching dataset metadata
FEATURE_SERVICE_DATASET_METADATA_TIMEOUT_SECONDS=60

# Timeout in seconds for downloading dataset files from Feature Service API (default: 600 seconds = 10 minutes)
# Increase for very large datasets or slow network connections
FEATURE_SERVICE_DATASET_DOWNLOAD_TIMEOUT_SECONDS=600

# Polling interval in seconds for checking dataset build status
# Used when waiting for dataset.ready notification
FEATURE_SERVICE_DATASET_POLL_INTERVAL_SECONDS=60

# Storage path for downloaded dataset files (Parquet format)
# Datasets are downloaded from Feature Service and stored locally for training
FEATURE_SERVICE_DATASET_STORAGE_PATH=/datasets

# Legacy feature compatibility mode (for models trained before Feature Service integration)
# Set to 'true' only if you have old models that require legacy feature names (e.g., spread_percent)
# New models should be trained on Feature Service features directly (set to 'false')
# WARNING: This is a temporary workaround. Models should be retrained on Feature Service features.
FEATURE_SERVICE_LEGACY_FEATURE_COMPATIBILITY=false

# =============================================================================
# Raw Data Storage Configuration
# =============================================================================
# Base directory for raw market data storage (Parquet files)
# Data is organized by type and date: data/raw/{type}/{date}/{symbol}.parquet
RAW_DATA_STORAGE_PATH=/data/raw

# Data retention period in days (default: 90 days)
RAW_DATA_RETENTION_DAYS=90

# =============================================================================
# Dataset Storage Configuration
# =============================================================================
# Base directory for dataset storage (Parquet files)
# Datasets are stored as: data/datasets/{dataset_id}/{split}.parquet
DATASET_STORAGE_PATH=/data/datasets

# =============================================================================
# Feature Registry Configuration
# =============================================================================
# Path to default Feature Registry YAML configuration file
FEATURE_REGISTRY_CONFIG_PATH=/app/config/feature_registry.yaml

# Feature Registry Version Management Configuration
# Directory for Feature Registry version files (YAML files stored as source of truth)
FEATURE_REGISTRY_VERSIONS_DIR=/app/config/versions

# Use database-driven version management (true) or file-only mode (false)
# Default: true - enables version management via database with files as source of truth
FEATURE_REGISTRY_USE_DB=true

# Automatically migrate legacy feature_registry.yaml to versioned storage on startup
# Default: true - automatically migrates existing feature_registry.yaml to versions/ directory
FEATURE_REGISTRY_AUTO_MIGRATE=true

# =============================================================================
# Feature Computation Configuration
# =============================================================================
# Feature computation intervals (comma-separated: 1s,3s,15s,1m)
FEATURE_COMPUTATION_INTERVALS=1s,3s,15s,1m

# Latency warning threshold in milliseconds (default: 70ms)
FEATURE_COMPUTATION_LATENCY_WARNING_MS=70

# =============================================================================
# Data Quality Configuration
# =============================================================================
# Enable data quality monitoring (default: true)
DATA_QUALITY_MONITORING_ENABLED=true

# Data quality report generation timeout in seconds (default: 5 seconds)
DATA_QUALITY_REPORT_TIMEOUT_SECONDS=5

# =============================================================================
# Symbols Configuration
# =============================================================================
# Comma-separated list of symbols to process (e.g., BTCUSDT,ETHUSDT)
# If empty, service will subscribe to all available symbols from ws-gateway
FEATURE_SERVICE_SYMBOLS=

# =============================================================================
# Historical Data Backfilling Configuration
# =============================================================================
# Delay between API requests in milliseconds to respect rate limits (default: 100ms)
# Used by backfilling service when fetching historical data from Bybit REST API
FEATURE_SERVICE_BACKFILL_RATE_LIMIT_DELAY_MS=100
# Enable/disable backfilling feature (default: true)
FEATURE_SERVICE_BACKFILL_ENABLED=true
# Enable/disable automatic backfilling when data insufficient (default: true)
FEATURE_SERVICE_BACKFILL_AUTO=true
# Maximum days to backfill in one operation (default: 90)
FEATURE_SERVICE_BACKFILL_MAX_DAYS=40
# Default kline interval in minutes for backfilling (default: 1 = 1 minute)
FEATURE_SERVICE_BACKFILL_DEFAULT_INTERVAL=1
# Note: Backfilling uses Bybit REST API public endpoints and does not require API keys for market data

# =============================================================================
# Model Storage Configuration
# =============================================================================
# Directory for model files (mounted as Docker volume)
MODEL_STORAGE_PATH=/models

# =============================================================================
# Model Training Configuration
# =============================================================================
# Minimum number of records required to start model training
MODEL_TRAINING_MIN_DATASET_SIZE=1000

# Maximum duration for model training in seconds (30 minutes default)
MODEL_TRAINING_MAX_DURATION_SECONDS=1800

# Minimum accuracy threshold for model activation (0.0 to 1.0)
MODEL_QUALITY_THRESHOLD_ACCURACY=0.75

# Scheduled retraining schedule (cron format, optional)
# Example: "0 2 * * *" for daily at 2 AM

# Class Balancing Configuration
# =============================================================================
# Enable SMOTE oversampling for minority classes (default: false)
# SMOTE generates synthetic samples for minority classes to balance the dataset
# Use for severe class imbalance. Note: increases training time and memory usage
MODEL_TRAINING_USE_SMOTE=false

# Class weight calculation method for multi-class classification
# Options: "inverse_frequency" (default), "balanced" (sklearn), "custom"
# - "inverse_frequency": weight = total_samples / (num_classes * class_count)
# - "balanced": uses sklearn.utils.class_weight.compute_class_weight("balanced")
# - "custom": use custom weights from configuration (not yet implemented)
MODEL_TRAINING_CLASS_WEIGHT_METHOD=inverse_frequency

# Hyperparameter Tuning Configuration
# =============================================================================
# Enable hyperparameter optimization (default: false)
# When enabled, model training will perform hyperparameter search before training
# Note: significantly increases training time, use only for model improvement iterations
MODEL_TRAINING_HYPERPARAMETER_TUNING=false

# Hyperparameter tuning method
# Options: "grid_search" (default), "bayesian"
# - "grid_search": exhaustive search over parameter grid
# - "bayesian": Bayesian optimization using scikit-optimize or optuna
MODEL_TRAINING_TUNING_METHOD=grid_search

# Maximum iterations for hyperparameter tuning (default: 50)
# Limits the number of parameter combinations to evaluate
MODEL_TRAINING_TUNING_MAX_ITERATIONS=50

# Data Quality Validation Configuration
# =============================================================================
# Enable data quality checks before training (default: true)
# Checks for missing values, infinite values, constant features, duplicates, data leakage
MODEL_TRAINING_QUALITY_CHECKS_ENABLED=true
MODEL_RETRAINING_SCHEDULE=

# Timestamp Continuity Validation Configuration
# =============================================================================
# Minimum acceptable timestamp coverage ratio for training datasets (0.0-1.0, default: 0.8 = 80%)
# Datasets with coverage below this ratio will trigger warnings
# Lower coverage may indicate missing data periods that could affect model training quality
MODEL_TRAINING_MIN_DATASET_COVERAGE_RATIO=0.8

# Enable warnings for large timestamp gaps in training datasets (default: true)
# Large gaps may indicate missing trading sessions or data collection issues
MODEL_TRAINING_WARN_ON_LARGE_GAPS=true

# Critical gap threshold in seconds (default: 3600 = 1 hour)
# Gaps exceeding this duration will trigger warnings
# Gaps larger than this may significantly affect temporal dependencies in model training
MODEL_TRAINING_CRITICAL_GAP_THRESHOLD_SECONDS=3600

# =============================================================================
# Time-Based Retraining Configuration (for market-data-only training)
# =============================================================================
# Interval in days for time-based retraining (default: 7 days)
# Model will be retrained when this many days have passed since last training
MODEL_RETRAINING_INTERVAL_DAYS=7

# Training period length in days for dataset building (default: 30 days)
# Number of days of historical data to use for training split
MODEL_RETRAINING_TRAIN_PERIOD_DAYS=30

# Validation period length in days for dataset building (default: 7 days)
# Number of days of historical data to use for validation split
MODEL_RETRAINING_VALIDATION_PERIOD_DAYS=7

# Test period length in days for dataset building (default: 1 day)
# Number of days of historical data to use for test split
MODEL_RETRAINING_TEST_PERIOD_DAYS=1

# Prediction horizon in seconds for model training (default: 60 seconds = 1 minute)
# This determines how far into the future the model predicts price movements
MODEL_PREDICTION_HORIZON_SECONDS=60

# Classification threshold for target computation (default: 0.005 = 0.5%)
# Price movement must exceed this threshold to be classified as 'up' or 'down'
# Values below threshold are classified as 'flat'
MODEL_CLASSIFICATION_THRESHOLD=0.005

# Dataset Quality Control Configuration
# Maximum ratio of NaN values per feature column (0.0-1.0, default: 0.5 = 50%)
# Features with NaN ratio above this threshold will be logged as warnings
DATASET_MAX_FEATURE_NAN_RATIO=0.5

# Maximum ratio of NaN values per row across all features (0.0-1.0, default: 0.8 = 80%)
# Rows with NaN ratio above this threshold will be dropped from dataset
DATASET_MAX_ROW_NAN_RATIO=0.8

# Minimum ratio of valid (non-NaN) features per row (0.0-1.0, default: 0.3 = 30%)
# Rows with valid features ratio below this threshold will be dropped from dataset
DATASET_MIN_VALID_FEATURES_RATIO=0.3

# Fail dataset build if any feature has NaN ratio above threshold (default: false)
# If true, dataset build will fail when features exceed DATASET_MAX_FEATURE_NAN_RATIO
# If false, only warnings will be logged and problematic features will be kept
DATASET_FAIL_ON_HIGH_NAN_RATIO=false

# =============================================================================
# DEPRECATED: Execution Events Buffer Configuration (for backward compatibility)
# =============================================================================
# NOTE: These variables are deprecated for training pipeline (which now uses
# market-data-only training via Feature Service). They may still be used for
# quality monitoring or other purposes. Will be removed in future versions.

# Enable persistent buffer for training orchestrator so that unused execution
# events can be recovered from database after service restart.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_PERSISTENCE_ENABLED=true

# Enable automatic buffer recovery on startup. When enabled, the service will
# load execution events that have not yet been used for training into the
# in-memory buffer on startup.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_RECOVERY_ON_STARTUP=true

# Maximum number of execution events to recover on startup.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BUFFER_MAX_RECOVERY_EVENTS=10000

# Enable training queue to avoid cancelling in-progress training when new data
# arrives. New training requests are queued and processed sequentially.
TRAINING_QUEUE_ENABLED=true

# Maximum size of the training queue (number of pending training requests).
TRAINING_QUEUE_MAX_SIZE=10

# Allow CRITICAL priority retraining (e.g., severe quality degradation) to
# cancel the current training when enabled. Default is false.
TRAINING_FORCE_CANCEL_ON_CRITICAL=false

# Maximum number of parallel training tasks allowed (per service instance).
# Current implementation runs trainings sequentially but this value is reserved
# for future parallelization support.
MAX_PARALLEL_TRAINING=1

# Interval in seconds for batch buffer update operations in the training
# orchestrator. Used to reduce write frequency when persisting buffer state.
# DEPRECATED: Not used for training pipeline (market-data-only training)
BATCH_BUFFER_UPDATE_INTERVAL_SECONDS=10

# =============================================================================
# Signal Generation Configuration
# =============================================================================
# Rate limit for signal generation (signals per minute)
SIGNAL_GENERATION_RATE_LIMIT=60

# Burst allowance for rate limiting (additional signals allowed in burst)
SIGNAL_GENERATION_BURST_ALLOWANCE=10

# Skip signal generation if open order exists for same asset and strategy
# Set to 'true' to prevent duplicate orders, 'false' to allow multiple signals
SIGNAL_GENERATION_SKIP_IF_OPEN_ORDER=true

# Check only opposite direction orders when skipping (e.g., skip buy signal if sell order exists)
# Set to 'true' to check only opposite direction orders, 'false' to check all orders
# Only used when SIGNAL_GENERATION_SKIP_IF_OPEN_ORDER=true
SIGNAL_GENERATION_CHECK_OPPOSITE_ORDERS_ONLY=false

# Enable warm-up mode when no trained model exists
WARMUP_MODE_ENABLED=true

# Warm-up signal generation frequency (signals per minute)
WARMUP_SIGNAL_FREQUENCY=1

# Minimum order amount for warm-up signals (in quote currency)
WARMUP_MIN_AMOUNT=100.0

# Maximum order amount for warm-up signals (in quote currency)
WARMUP_MAX_AMOUNT=1000.0

# Randomness level for warm-up signals (0.0 = deterministic, 1.0 = fully random)
WARMUP_RANDOMNESS_LEVEL=0.5

# Safety margin for balance adaptation (portion of available balance that can be used, 0.0-1.0]
# Example: 0.95 means use up to 95% of available balance when adapting amounts
BALANCE_ADAPTATION_SAFETY_MARGIN=0.95

# Maximum acceptable age of balance data (in seconds). Older balance snapshots are treated as stale
# and will cause signal generation to skip due to unreliable balance information.
BALANCE_DATA_MAX_AGE_SECONDS=60

# Maximum acceptable age of cached market data (in seconds). If market data is older than this
# value, signal generation will treat it as stale and skip to avoid decisions on outdated prices.
MARKET_DATA_MAX_AGE_SECONDS=60

# Warning threshold for cached market data staleness (in seconds). When market data age is above
# this value but below MARKET_DATA_MAX_AGE_SECONDS, warnings are logged but data is still used.
MARKET_DATA_STALE_WARNING_THRESHOLD_SECONDS=30

# Alert threshold for signal processing delay (in seconds). When the time between signal creation
# and publication exceeds this threshold, a warning is logged and metrics are updated for monitoring.
SIGNAL_PROCESSING_DELAY_ALERT_THRESHOLD_SECONDS=300

# Enable on-demand balance sync via ws-gateway when model-service detects that balance
# snapshots in the account_balances table are stale or missing. When enabled, the
# model-service will call ws-gateway /api/v1/balances/sync before re-reading the table.
BALANCE_SYNC_ENABLED=true

# Minimum interval (in seconds) between successive balance sync requests from model-service.
# This protects ws-gateway and Bybit API from being spammed when multiple signals are generated.
BALANCE_SYNC_MIN_INTERVAL_SECONDS=30

# Timeout (in seconds) for HTTP requests from model-service to ws-gateway balance sync endpoint.
BALANCE_SYNC_TIMEOUT_SECONDS=5.0

# Risk Management Configuration for Model Service
# =============================================================================
# Take profit threshold (as percentage of unrealized PnL)
# When position unrealized PnL exceeds this threshold, model-service will generate
# a SELL signal to close the position
MODEL_SERVICE_TAKE_PROFIT_PCT=3.0

# Maximum position size ratio (0.0-1.0) for portfolio diversification
# This is a normalized ratio relative to total portfolio exposure
# Currently not used - see ORDERMANAGER_MAX_POSITION_SIZE for absolute limit
MODEL_SERVICE_MAX_POSITION_SIZE_RATIO=0.8

# =============================================================================
# Exit Strategy Configuration
# =============================================================================
# Enable position-based exit strategy evaluation
EXIT_STRATEGY_ENABLED=true

# Rate limit for exit signal generation (signals per asset per minute)
EXIT_STRATEGY_RATE_LIMIT=10

# Take Profit Configuration
# Note: Take profit threshold now uses MODEL_SERVICE_TAKE_PROFIT_PCT (unified with intelligent signal generator)
TAKE_PROFIT_ENABLED=true
TAKE_PROFIT_PARTIAL_EXIT=false
TAKE_PROFIT_PARTIAL_AMOUNT_PCT=50.0

# Stop Loss Configuration
STOP_LOSS_ENABLED=true
STOP_LOSS_THRESHOLD_PCT=-2.0

# Trailing Stop Configuration
TRAILING_STOP_ENABLED=false
TRAILING_STOP_ACTIVATION_PCT=2.0
TRAILING_STOP_DISTANCE_PCT=1.0

# Time-Based Exit Configuration
TIME_BASED_EXIT_ENABLED=false
TIME_BASED_EXIT_MAX_HOURS=24
TIME_BASED_EXIT_PROFIT_TARGET_PCT=1.0

# =============================================================================
# Trading Strategy Configuration
# =============================================================================
# Comma-separated list of trading strategy identifiers
# Example: momentum_v1,mean_reversion_v1
TRADING_STRATEGIES=

# =============================================================================
# Order Manager Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4600)
ORDERMANAGER_PORT=4600

# API key for REST API authentication
# Other microservices use this key to authenticate with Order Manager
ORDERMANAGER_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
ORDERMANAGER_LOG_LEVEL=INFO

# Service identifier
ORDERMANAGER_SERVICE_NAME=order-manager

# =============================================================================
# Order Execution Configuration
# =============================================================================
# Enable dry-run mode (process signals but do not send orders to Bybit)
# Set to 'true' for testing without real orders
ORDERMANAGER_ENABLE_DRY_RUN=false

# Maximum order size for single order (in USDT)
# Orders exceeding this size may be split if order splitting is enabled
# NOTE: This parameter is defined but NOT currently used in code checks.
# Real validation uses: MAX_EXPOSURE × MAX_ORDER_SIZE_RATIO
# Keeping it for future use or documentation purposes
ORDERMANAGER_MAX_SINGLE_ORDER_SIZE=500.0

# Enable order splitting for large amounts
# When enabled, large orders are split into multiple smaller orders
ORDERMANAGER_ENABLE_ORDER_SPLITTING=false

# Timeout for order creation API calls (in seconds)
ORDERMANAGER_ORDER_EXECUTION_TIMEOUT=30

# =============================================================================
# Risk Limits Configuration
# =============================================================================
# Maximum position size per asset (in base currency)
# Note: Should accommodate existing positions (e.g., 1.19 ETH), so set to 2.0 to allow reasonable position sizes
ORDERMANAGER_MAX_POSITION_SIZE=2.0

# Maximum total exposure across all positions (in USDT)
# Used in combination with MAX_ORDER_SIZE_RATIO to calculate max order size
# Max order size = MAX_EXPOSURE × MAX_ORDER_SIZE_RATIO = 10000 × 0.1 = 1000 USDT
ORDERMANAGER_MAX_EXPOSURE=10000.0

# Maximum order size as ratio of maximum exposure (0.0 to 1.0)
# Example: 0.1 means maximum 10% of MAX_EXPOSURE per order
# Max order size = 10000 × 0.1 = 1000 USDT (to limit orders to $1000 equivalent)
ORDERMANAGER_MAX_ORDER_SIZE_RATIO=0.1

# =============================================================================
# Bybit API Retry Configuration
# =============================================================================
# Maximum retry attempts for Bybit API calls
ORDERMANAGER_BYBIT_API_RETRY_MAX_ATTEMPTS=3

# Base delay for exponential backoff (in seconds)
ORDERMANAGER_BYBIT_API_RETRY_BASE_DELAY=1.0

# Maximum delay between retries (in seconds)
ORDERMANAGER_BYBIT_API_RETRY_MAX_DELAY=30.0

# Exponential backoff multiplier
ORDERMANAGER_BYBIT_API_RETRY_MULTIPLIER=2.0

# =============================================================================
# Order Type Selection Configuration
# =============================================================================
# Confidence threshold for market orders (0.0 to 1.0)
# Signals with confidence above this threshold may use market orders
ORDERMANAGER_MARKET_ORDER_CONFIDENCE_THRESHOLD=0.9

# Spread threshold for market orders (as percentage)
# Market orders may be used when spread is below this threshold
ORDERMANAGER_MARKET_ORDER_SPREAD_THRESHOLD=0.1

# Price offset ratio for limit orders (0.0 to 1.0)
# Used to calculate limit price offset from market price
ORDERMANAGER_LIMIT_ORDER_PRICE_OFFSET_RATIO=0.5

# =============================================================================
# Position Management Configuration
# =============================================================================
# Interval for position snapshots (in seconds)
# Position state is periodically snapshotted for historical tracking
ORDERMANAGER_POSITION_SNAPSHOT_INTERVAL=300

# Interval for position validation (in seconds)
# Position state is validated against computed position from order history
ORDERMANAGER_POSITION_VALIDATION_INTERVAL=3600

# =============================================================================
# Pending Order Cancellation Configuration
# =============================================================================
# Timeout in minutes after which pending orders will be automatically cancelled
# Pending orders that exceed this timeout are considered stale and will be cancelled
# to prevent orders from hanging indefinitely
ORDERMANAGER_PENDING_ORDER_TIMEOUT_MINUTES=5

# Interval in seconds for checking pending orders that exceed timeout
# The task runs periodically to find and cancel stale pending orders
ORDERMANAGER_PENDING_ORDER_CHECK_INTERVAL=60

# =============================================================================
# Order Cancellation Configuration
# =============================================================================
# If true, only cancel orders with opposite direction (buy vs sell)
# If false, cancel all pending orders for same asset when new signal arrives
ORDERMANAGER_CANCEL_OPPOSITE_ORDERS_ONLY=false

# Automatically cancel orders older than this timeout (in seconds)
# Set to 0 to disable automatic cancellation of stale orders
ORDERMANAGER_CANCEL_STALE_ORDER_TIMEOUT=3600

# =============================================================================
# Risk Management Configuration
# =============================================================================
# Unrealized loss warning threshold (as percentage)
# Warning is logged when position unrealized loss exceeds this threshold
ORDERMANAGER_UNREALIZED_LOSS_WARNING_THRESHOLD=10.0

# Enable balance check before order creation (default: true)
# If false, balance validation is skipped - Bybit API will reject orders with insufficient balance anyway.
# Setting to false reduces API calls and improves performance, but loses early rejection and detailed logging.
ORDERMANAGER_ENABLE_BALANCE_CHECK=true

# Enable automatic order size reduction when insufficient balance error (110007) occurs (default: true)
# If true, system will try to reduce order size based on available balance and retry order creation.
# If false, orders will be immediately rejected when 110007 error occurs.
ORDERMANAGER_ENABLE_ORDER_SIZE_REDUCTION=true

# =============================================================================
# Position Manager Service Configuration
# =============================================================================
# REST API port (non-standard port starting from 4800)
POSITION_MANAGER_PORT=4800

# API key for REST API authentication
# Other microservices use this key to authenticate with Position Manager
POSITION_MANAGER_API_KEY=XXXX

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
POSITION_MANAGER_LOG_LEVEL=INFO

# Service identifier
POSITION_MANAGER_SERVICE_NAME=position-manager

# =============================================================================
# Position Management Configuration
# =============================================================================
# Interval for position snapshots (in seconds)
# Position state is periodically snapshotted for historical tracking
POSITION_MANAGER_SNAPSHOT_INTERVAL=3600  # 1 hour

# Retention period for position snapshots (in days)
# Snapshots older than this period are automatically deleted
POSITION_MANAGER_SNAPSHOT_RETENTION_DAYS=365

# Interval for position validation (in seconds)
# Position state is validated against authoritative sources
POSITION_MANAGER_VALIDATION_INTERVAL=1800  # 30 minutes

# Portfolio metrics cache TTL (in seconds)
# Metrics are cached in memory and invalidated on position updates
POSITION_MANAGER_METRICS_CACHE_TTL=10

# =============================================================================
# Position Update Strategy Configuration
# =============================================================================
# Use WebSocket average price for position updates
# If true, WebSocket avgPrice is used when difference exceeds threshold
POSITION_MANAGER_USE_WS_AVG_PRICE=true

# Average price difference threshold (as ratio, e.g., 0.001 = 0.1%)
# WebSocket avgPrice is used if difference from existing value exceeds this threshold
POSITION_MANAGER_AVG_PRICE_DIFF_THRESHOLD=0.001  # 0.1%

# Position size validation threshold (as ratio)
# Size discrepancies exceeding this threshold trigger validation
POSITION_MANAGER_SIZE_VALIDATION_THRESHOLD=0.0001

# Price staleness threshold (in seconds)
# External API is queried if price is older than this threshold
POSITION_MANAGER_PRICE_STALENESS_THRESHOLD=300  # 5 minutes

# External price API timeout (in seconds)
POSITION_MANAGER_PRICE_API_TIMEOUT=5

# External price API retry attempts
POSITION_MANAGER_PRICE_API_RETRIES=3

# Optimistic locking retry attempts
# Number of retries when version conflict occurs during position update
POSITION_MANAGER_OPTIMISTIC_LOCK_RETRIES=3

# Optimistic locking backoff base delay (in milliseconds)
# Exponential backoff starts from this value (100ms, 200ms, 400ms)
POSITION_MANAGER_OPTIMISTIC_LOCK_BACKOFF_BASE=100

# Enable timestamp-based size conflict resolution between WebSocket and Order Manager
# When enabled, WebSocket size may update DB size if its event timestamp is fresher
POSITION_MANAGER_ENABLE_TIMESTAMP_RESOLUTION=true

# Optional tolerance window (in seconds) when comparing timestamps
# WebSocket timestamp must be greater than (order_timestamp + tolerance) to win
POSITION_MANAGER_TIMESTAMP_TOLERANCE_SECONDS=0

# =============================================================================
# Rate Limiting Configuration
# =============================================================================
# Enable rate limiting for API endpoints
POSITION_MANAGER_RATE_LIMIT_ENABLED=true

# Default rate limit (requests per minute)
# Applied to all API keys unless overridden
POSITION_MANAGER_RATE_LIMIT_DEFAULT=100

# Rate limit overrides per API key (comma-separated key:limit pairs)
# Example: model-service-key:100,risk-manager-key:200,ui-key:1000
POSITION_MANAGER_RATE_LIMIT_OVERRIDES=model-service-key:100,risk-manager-key:200,ui-key:1000

# =============================================================================
# Grafana Monitoring Service Configuration
# =============================================================================
# Grafana UI port (non-standard port starting from 4700)
GRAFANA_PORT=4700

# Grafana admin user credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=XXXX

# Grafana PostgreSQL read-only user credentials
# This user is created by migration and has SELECT permissions on monitoring tables
GRAFANA_POSTGRES_USER=grafana_monitor
GRAFANA_POSTGRES_PASSWORD=XXXX
